%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Template Bachelor-Arbeit
% Forschungsgruppe Datenbanken und Informationssysteme
% Universität Innsbruck
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% include file containing tex configurations
\input{config.tex}
\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{float}
\usepackage{wrapfig}
%test
\colorlet{newcode}{blue!40!black!40!green}

% start document
\begin{document}
\parindent 0cm 

\bibliographystyle{dbis}



%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% TITELSEITE
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\begin{titlepage}

\begin{center}
% insert university logo
\includegraphics[width=30mm]{unilog4c} \\[3mm]

\begin{large}
Leopold-Franzens-Universität Innsbruck\\[5mm]
Institut für Informatik\\
Datenbanken und Informationssysteme\\[25mm]
\end{large}

\begin{LARGE} Development of an OpenSource Feedbackcommuncationplatform\end{LARGE}

\begin{footnotesize}Bachelor-Arbeit\end{footnotesize}\\[15mm]

Martin Karrer \\[30mm]


betreut von\\
Wolfgang Gassler und Eva Zangerle\\[10mm]


\begin{footnotesize}Innsbruck, \today \end{footnotesize}
\end{center}
\end{titlepage}




%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% ABSTRACT / ZUSAMMENFASSUNG
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\cleardoublepage
\pagenumbering{Roman}
\thispagestyle{plain}
\renewcommand{\abstractname}{Abstract}
\begin{abstract}
Within this work, the development process of an open-source feedback collecting tool with the ability to communicate with the feedback-giving-person and the maintainer has been documented. 
Most feedback applications only offer a one-way communication from the feedback-giving-person to the feedback-requester. The approach of how this system has been developed with the ability to communicate or discuss a feedback, will be described in detail later on. This system is extendable, scale-able and especially easy to maintain and install.

All techniques and patterns used in this project to implement the single-page-application will be described in the relevant chapter. This project tries to show the utilisation of a functional language in everyday life and all advantages and disadvantages which have occurred during the implementation of said project. 

The aim of the presented application is to be a minimal but extendable and scale-able open-source platform used for requesting and discussing feedback.
\end{abstract}



%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% DANKSAGUNG
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
%\cleardoublepage
%\thispagestyle{plain}
%\chapter*{Danksagung}




%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% VORWORT
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
%\cleardoublepage
%\thispagestyle{plain}
%\chapter*{Vorwort}


%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% INHALTSVERZEICHNIS
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\cleardoublepage
\pagestyle{fancy}
\tableofcontents 

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% CHAPTER 1 
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

% chapter starts on right side
\cleardoublepage

\chapter{Introduction}

% change numbering to normal format, set page counter to 1
\pagenumbering{arabic}
\setcounter{page}{1}

Getting honest feedback is in itself a challenge and it is even harder if it is not possible to collect this feedback anonymously. To be able to gain anonymous feedback the system has to accept feedback with and without user information. This application collects feedback and then makes it possible to discuss the content separately afterwards.


An e-mail mailbox or some online discussion board is commonly used to collect feedback. Most of these online services do not scale for the user or the system. 
For example: We held a presentation in front of 400 people and now we want to know if the audience liked it? Sending an e-mail containing feedback does not scale. Even in the best case scenario, with a feedback-friendly audience, one will get over 400 messages in ones inbox. Managing feedback in a discussion board can be a huge hassle if one wants to find and manage the feedback without spending more than a thought on specifically discussing one of the feedback entries.

In this project the main goal was to create an online platform, where anyone is allowed to create a feedback-channel with a specific topic. In this channel the users are able to post feedback anonymously or provide their identity as they please. Each feedback in those channels can be up-voted or down-voted and every user can reply to a specific feedback to discuss or clarify misunderstandings. The administrator of the channel is not restricted by any rules and can also collect universal feedback through not being constricted by predetermined questions. Therefore Constructeev will not provide a predefined questionnaire but the user can write down his/her own view instead and make suggestions for improvement. This will result in better and more widespread feedback.

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% KAPITEL 2
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\cleardoublepage
\chapter{Requirement Specification}


A description of the software requirements for Constructeev will follow below. This chapter mainly describes the necessary requirements for the application while Chapter 5 wil give a deep insight into the development process.  
 
\section{General Requirments}
The application needs to be accessible from all kinds of devices, especially mobile-phones, tablets, notebooks and desktop workstations. Web technologies, like Javascript, CSS and HTML, ensure that the user only needs a HTML5 compatible browser, which is already pre-installed on all the devices listed above.
All relevant data needs to be stored permanently on a storage medium and has to be accessible at any given time. It is important to keep the data structured and it should be possible to change the database adapter and migrate data from one to another database system without any issues.

The application needs to be split into two segments, a client-application and a server-application. Both should run on as many platforms as possible without any constraints on productivity and scalability. 

\subsection{Server Application}
The server application should be scalable and runnable on virtually any operating system and platform. Furthermore it has to provide a uniform interface for the client application. In this case it will be a JSON-based REST-like API. The data storage has to be a common SQL-Database like Mysql or PostgreSQL. It should also be possible to exchange the database during installation time. 

\subsection{Client Application}
The server application as well as the client application need to be able to run on any platform, but on the same hand target end-user hardware with a display and a HTML5 compatible browser. AngularJS is used to build the single-page-application. Asynchrone API calls will communicate with the application server. 

\section{Server System Requirements}
The server system has to be easy to set up and to maintain. The application resulting from this project also runs as a public service available to anyone, which makes scalability an important key point. A channel with over 16.000 feedback entries should be as responsive and usable as one with only 20 feedback entries. 
Not only the amount of data has to scale, but the number of requests has to be easy to handle too by simply adding more servers. 

\section{Channel Components}
To create an easy to use application it is important to stay as minimalistic as possible. It is a channel's task to hold a specific quantity of feedback for a specific topic which is appointed by the channel admin. There always has to be one admin per channel. Users which need more than one channel will get separate login hashes for each of their channels. This makes sharing a company channel or community channel easier. 

\section{Feedback Components}
The feedback component holds all information about a feedback which is mainly important for the user. Whereas information which is relevant for the administrator is added to the feedback additionally. Trough this design the application gets faster in delivering a set of feedback entries. Feedback always belongs to a channel and is never orphaned. If a channel gets deleted, all its feedback entries will be deleted too. So feedback can never exist without its corresponding channel.

\section{Scalability}
Constructeev will be available as a reference service and does not limit users by quotas. Thus it was necessary to build an application which would scale easily. The main requirement was set by handeling 16.000 feedback entries  per channel without any performance loss or noticeable delay. It should be easy to setup a cluster, without having to change or recode the session management. It is not set or limited by the project in which direction to scale. Here we have two options: Vertical scaling is when the node gets upgraded with a faster CPU and more memory while horizontal scaling will add fully fledged servers to the system.

\section{Administrator View}
The administrator view displays the same content as the user view. But the feedback and channels with information that is considered irrelevant to the user will be hidden from the user view. A small management panel will be added to the top for the administratior. Inside this panel the administrator can change some basic channel settings. For instance he/she can open or close the channel, hide or view all feedback entries and a button which can change the channels description is enclosed.
Another feature which is only visible to the administrator is the so called "mark-a-feedback-read-or-unread-button". Through this button you can easily keep track which feedback entries  you have already seen and worked on and which ones you have not yet read. A feedback can also be favoured by the admin and then will be automatically marked with a star and a label saying "Fav". Through flagging a feedback with said star and label you can mark it as one of your favourites.


\chapter{Related Work}
This chapter will give an brief overview of some of the work which also specifies in coding feedback related programs as well a brief summary of how this bachelor thesis has been steered and influenced by others. There are plenty different feedback collecting tools. Most of them are for one single purpose, but all of them differ materially from this bachelor thesis.

\section{Arsnova}
Arsnova is an open source audiance-response-service and was developed by the "Technische Hochschule Mittelhessen". The aim of this service is to be a supportive application for lectures and seminars. It provides a live feedback channel for the pace of the lecture indicated by four emoticons. The happy emoticon represents "I can follow the lecture", the wink emoticon means "please be quicker", the surprised emoticon signals the teacher is progressing too fast and the sad smilie tells the lecturer that the students have lost the golden thread. 
With Arsnova students are able to ask questions anonymously. Those questions can be projected to the black board and thereby discussed with the lecturer. Teachers are able to create some questions beforehand which consist of multiple choice answers. The system then evaluates the student through the findings of those answers. 
The emerging results are aggregated by the system and then are accessible by the students for their own learing process and the lecturer can look at those results and thereby conclude how well his/her students have been answering the prepared questions.

\section{Feedback Button}
The feedbackbutton is a small widget button which can simply be added to any website. When this button is clicked, a pop-up window will be opened and a form will be presented to the user, where he/she has to fill in his/her name, e-mail address, feedback category and comment. The sent feedback is stored in a database on the company server. This tool is a commercial closed source for which the user pays a certain fee every month based on the approximate amount of feedback which will be sent. For instance  if one makes 50 feedback entries a month the person has to pay 6.00 \$ per month, for 400 feedback entries that would make 12.00 \$ per month, for 1200 feedback entries the fee would be 18 \$ per month and finally it would cost 99 \$ per month for unlimited feedback entries. But there is no way to customize the form or receive anonymous feedback.
 
\section{Feedbackify}
Feedbackify is a commercial company from the United Kingdom which offers a website feedback toolkit. Here it is not possible to create a feedback form without having to deploy a button on your own website. With this tool you can create and customized label and add your company logo to the online form. The feedback will be sent to the Feedbackify servers and the company promises prompt real-time feedback. A big drawback for the user is the fact that he/she has to expose his/her name or e-mail.  On the other hand it is easy for the administrator to group feedback into sections or campains. It is also possible to to see where the feedback comes from. Another con is the listing of sensitive data like your customer's geographic location, browser history and information about the used operating system as well as screen size and the IP-address.

\section{GetFeedback.com}
GetFeedback.com is a representation of the most popular feeback survey tool. Those tools are exellent to get answers to a specific set of questions, but they do not not cover maladministration outside of the scope of their questions. Sometimes there are not as many selectable options available as needed or the survey takes too long altogether. The statsitic which will be generated by the GetFeedback servers is nice to present and to have a visualisation, but it has to be pointed out that this can not cover every users opintion, and the result can steered by the asked questions. 

\chapter{Used Technologies} \label{used_tec}
In this chapter a brief overview of the technologies used in this project will be given since most of them are not widely used or known. Firstly, there will be an overview of the functional language called Elixir and some open source frameworks and modules which are used to build the application based on this fairly new language. The remaining chapter will describe the more commonly used front-end technologies as well as the server platform in use. 

\section{Elixir} \label{elixir_erlangVM}
Elixir is an alternative language for the Erlang Virtual Machine (ErlangVM) which allows the programmer to write code in a more compact and cleaner way than through using Erlang itself. You write your code in Elixir and compile it to a BEAM-Bytecode and run it like any byte-code from Erlang in the BEAM symmetric-multi-processor environment (beam.smp). BEAM stands for Bogdan/Björn's Erlang Abstract Machine, which has tried to compile the Erlang Code in an early Erlang version to C and thereby gain a better performance. Nowadays BEAM is a performant and a complete "process virtual machine" and does not compile code to C anymore, because the effort is too high for the result of a minimal performance gain on modern CPU systems.

The language Elixir is an open source project started by Jos\'e Valim and now is maintainedand developed by over 373 contributors. The source code of elixir can be found on the Github Repository at \url{https://github.com/elixir-lang/elixir}.

One major advantage of Elixir, it being a young programming language, is that the well tested, proven and hardened BEAM Virtual Machine is used for bytecode execution. A second advantage is that Elixir produces the same byte-code as Erlang, hence you can use Erlang libraries in Elixir and vice versa. Everything programmed in Erlang can also be programmed in Elixir and usually the Elixir code is as fast and performant as its Erlang counterpart.

Elixir provides a huge set of boilerplates, reduces duplication in code and also simplifies some important parts of the standard-library. It provides some syntactic sugar and is a nice tool for creating and packaging applications.

Another impressive feature offered by Elixir is Metaprogramming. This process makes it is easy to extend and define the language itself and one can basically write code which then continues to write the code for you. With macros you can abstract and uniform Elixir code parts to restructure and abstract more complex code away from the programmer. 
\subsection{Phoenix}
Phoenix is a web framework written in Elixir and it implements a server-side MVC pattern. 

Phoenix is very similar to other modern web-frameworks like Ruby on Rails or Python's Django. The core developer team of Phoenix tries to provide the best of both web-frameworks through providing Elixir and the ErlangVM. This results in a simple and elegant code as well as a high performance application running over multiple CPU's or even Nodes in real time. 

Let us look on how the Phoenix pipeline functions and which layers of this pipeline a single request will have to pass through: 


After a request was accepted by the cowboy webserver it will be handed over to the \textbf{endpoint}, which will apply all necessary functions, like those from the plug-system, to the request before it will be passed into the \textbf{router}. The router will parse the incoming request, discover the assigned controller and provide some helper functions for routes, paths and urls according to the controller. A pipeline can be specified in the controller, which makes encapsulation of different scopes and APIs simple. The router will pass the request on to the assigned \textbf{controller}. In this segment the functions, also known as actions, are called to provide the main functionality. The controller's main task is to prepair data and pass it into views, invoke the view rendering and/or perform http redirects. After the \textbf{view} got all the data it then renders a template and provides a self-defined helper function which can be used in the template. The view acts like an presentation layer in Phoenix. \textbf{Templates} are pre-compiled and are the only string concatenations in the background, thus blazing fast. 

Phoenix depends on some other projects in the Elixir and Erlang Ecosystem: 
\begin{itemize}
\item \textbf{cowboy:} lightweight super fast Erlang web server 
\item \textbf{ecto:} a query and database wrapper
\item \textbf{PhoenixHTML:} working with HTML and HTML safe strings
\item \textbf{Plug:} a specification and conveniences for composable modules in-between web applications
\item \textbf{poison:} a pure Elixir JSON library 
\item \textbf{Poolboy:} a worker pool factory 
\item \textbf{Ranch:} a socket acceptor pool
\end{itemize}

\subsection{Cowboy}
Cowboy is written in Erlang and is optimized to have a low latency period and a low memory usage. It uses Ranch for managing HTTP and socket connection. Cowboy is pure Erlang code and is easy to integrate on every platform without extra dependencies. This server provides a complete HTTP-stack with support for HTTP1.0, HTTP1.1, SPDY and web-sockets. The Cowboy project has a small and clean codebase, is well tested and provides a rich documentation.

\textcolor{newcode}{In this project Cowboy is used to accept and forward the request to the Phoenix framework. Cowboy is also able to keep socket connections which can be used in Phoenix channels for real-time communication between the client in JavaScript and its Elixir counterpart.}

\subsection{ETS}
ETS is an abbreviation for \textbf{E}rlang \textbf{T}erm \textbf{S}torage. ETS was built to hold a huge amount of data inside the Erlang runtime but constant access to the data has to be still possible. The ETS data is stored inside dynamic tables and each table is occupied by only one process. Those tables merely have a lifetime of one single process. If the process is terminated the data will be destroyed. Via message passing it is possible to request data from one process and give it to an other one. Message passing also works between nodes which concludes in all data being available throughout the whole cluster. 

\textcolor{newcode}{The ETS is used like a Redis database. It does run inside the ErlangVM and so not another dependency has to be installed  and maintained in the production system. It is possible to run the whole app as a Unikernel  \footnote{Minimal Operating System with the Application Code compiled into the Kernel} on Xen \footnote{Xen: x86 \& ARM Hypervisor \url{xenproject.org}} or bare-metal.}

\subsection{Ecto}
Ecto is not only a database wrapper it also provides macros for a nice query DSL inside Elixir, which means you do not have to escape queries. An adapter for the database you want to use is necessary. Ecto repositories are wrappers around the desired database. With Ecto repository, it is possible to create, update, destroy and drop custom queries.  Change-sets are brought by Ecto and provide filters and casting functionality for external parameters. Through this we get another security layer in front of the database.

\section{PostgreSQL}
PostgreSQL is a widely known open source relational database system. It runs on all major platforms like Windows, Unix deviates and Linux. It has full ACID (Atomicity, Consistency, Isolation, Durability) and supports all SQL 2011 standard statements like foreign keys, joins, views, triggers and varying other procedures.
 \textcolor{newcode}{PostgreSQL was used in this project, because with the Postgres adapter for Ecto it is super easy to deploy Constructeev on Amazon web-services. There the Amazon RedShift Database can be used without a single line of code having to be changed.}

\section{Schema}
In the schema shown in this section, the database normalization rules have been violated only for one single reason. This schema can be automatically transformed into a Riak DB format and then can be used inside the Erlang ecosystem. Through changing the Database from Mysql/PostgreSQL to Riak this process is no problem and can be easily achieved.

\section{AngularJS}
AngularJS is a JavaScript framework for building client web applications with dynamic views. This framework is used to build HTML single-page-applications and supports a full model-view-controller-pattern and has its own router-module for managing views. Data inside the controller and model are usually two-way binded. Any changes in the view are visible inside the controller and vice-versa.
\textcolor{newcode}{AngularJS is used for the whole front-end funcitonality. Routing and views are done by an Angular-router replacement called ui-router. Ui-router allows to route and manage nested-views and and nested-states, which are not completely performant and easy with the standard router that is shipped with Angular-JS.}

\section{Semantic-UI}
Semantic-UI is an open source development framework for a responsive design. Natural language is used to describe the class names of HTML containers and it provides a nice and clean codebase for theming and adding customary extensions. 

\section{Server-Platform}
This section describes other software and hardware used for developing and testing the Constructeev system. Basically the system should be runnable if a network stack is available and the minimum set of both external dependencies (ErlangVM and Postgres) is fullfilled. 
It is also possible to use the RiakDB and a small kernel with ErlangVM. The complete code of Constructeev will be compiled into the kernel.
\newline
The application was developed on a Macbook Pro 15,6" running with Macintosh OS 10.11 (El Capitan) with an Intel Core i7 (r) 4 Core Processor with Hyperthreading up to 8 "virtual" Cores. SSD powered, where Postgres mySQL and Riak had their persistent data. 

\subsection{Tested Hardware}
In this section some hardware combinations will be shown. Further an explanation in what ways the software has been tested and developed will follow. Benchmarks will be described in chapter \ref{Performance and Scalability}. Some of them are rather specific like for instance the ARM-Server platform. 

\subsubsection{University of Innsbruck}
The Database and Information System Group from the University of Innsbruck created and granted access to a virtual CentOS7 machine with a single core virtual x86/amd64 CPU core with a clockrate of 2666MHz and 30GB SSD based storage. The application can be installed via the included shell script without problems.

\subsubsection{Scaleway ARM Server}
Scaleway ARM Server hosting platfrom. It offers some interesting services. Bare Metal ARM Servers, which are a custom build system on a chip with 4 ARM Cores (1.6GHz Clock) 4GB RAM and 50GB SSD disk, which offers only one IPv4 adress per server and 200Mbit/s external and 1Gbit/s internal bandwidth. The 1Gbit/s internal link is perfect for the communication between the cluster nodes. 

\subsubsection{Custom AMD 16 Core two CPU Server} 
This custom AMD Server has two CPU Sockets (both filled with the same Opteron Server CPU) and is the test system for the \textbf{s}ymmetric \textbf{m}ulti\textbf{p}rocessing (smp) functionality in Constructeev. SMP Systems share the main memory with all CPU's, hence all devices and common resources are available to all CPUs. Those multi-processor-systems work under one single operating system. Therefore you only have to start a single instance of the BEAM/ErlangVM. Elixir will discover the available cores on the installed CPU and spawn a single OS-process on every CPU and one OS-thread per core. Message passing and auto-discovery of the ErlangVM will glue those CPUs together to a single 16core ErlangVM node. The hardware specification of this server are two 8-core Opteron 6320, 32GB main memory, 12TB ZFS Raidz1 storage with a 256GB SSD cache, 10Gbit/s network interface card with 1Gbit/s internet connection. FreeBSD 10.1, an unixoid operating system was installed underneath the ErlangVM

% \subsubsection{Digital Ocean Droplet}

\chapter{Implementation}
In this chapter, the explanation of the implementation of the Constructeev application will be given. First of all there will be an overview of the whole system, divided into the back-end written in Elixir and the front-end where Javascript and CSS have been used. 
Further on a deep dive into how it is possible to scale with multiple nodes \textcolor{newcode}{ and why Elixir has been chosen as programming language} will follow.
As already described in chapter \ref{used_tec} the application has not been developed from ground up, therefore some dependencies to other open-source projects from the Elixir and Erlang community exist. Those modules are used especially for accepting and routing HTTP calls, escaping springs in HTML-safe responses and accessing the databases and file systems. In this project an external API is also requested for the channel and user avatars. All used modules are available on the Elixir package management system called "mix" and will be installed automatically with 'mix get.deps'. The process of evaluating those external dependencies costs time, but is important for building a distributed and scaleable system. It is highly important to confirm that non of those dependencies add a bottleneck to your application. There will be more  about the topic of scaling in chapter \ref{perf_scale}

A graph-diagram will show the schematic setup of all microservices and how they work together. 

\begin{figure}[!ht]
  \caption{System Schema}
  \centering
    \includegraphics[width=1\textwidth]{images/Constructeev.pdf}
\end{figure}


This single-page-app typically loads at the base of the first request, which includes the base structure of the application. Everything else will lazy loaded for more responsiveness. The web-app communicates, in a specific way for modern web applications, via a single HTTP/1.1 opened connection with a REST-API with JSON being the payload format. JSON (JavaScript Object Notation) is preferred over XML, because it is natively supported in JavaScript and you can work without having to extra parse the servers response. JSON is also less redundant, hence it does not open a field with '<field name>' and closes again with almost the same string '</field name>'.
 
\section{Back-end}
The back-end is written in Elixir, runs inside an ErlangVM (see section \ref{elixir_erlangVM}) and uses cowboy for accepting HTTP requests. The Phoenix framework is used to route and apply functions to the request and respond. Data is stored in a database which supports the SQL 2011 standard (like mysql, mariadb, PostgreSQL, Amazon Redshift etc.) or the RiakDB (recommend in distributed mode). For more Information see chapter \ref{perf_scale}).

\subsection{Selection of the proper programming language}
\textcolor{newcode}{The first prototype was built in Ruby and used the Ruby-on-Rails web framework. Many modern websites are built with Ruby-on-Rails, Github being a popular example. \cite{RORBW} \cite{DoesWhat}. While working on a company project, Elixir was discovered and Chris McCord, the creator of the phoenix framework presented the new version of this framework on EixirConf2015.
The language concept of Elixir and the combination of the Phoenix framework seemed perfect for this project. Also the ability to keep a state for something, like a chat over multiple nodes, is perfect for some future feature implementation. \footnote{more in conclusion}}
\textcolor{newcode}{
After rebuilding the prototype within a few hours, the first impact of the thin web framework and the fast web-server was revealed. Requests which took 3-6ms in Ruby-on-Rails now took 700$\mu$s to be on the server.
The developing process was a pleasure through Elixir and the ErlangVM is known to be a stable platform. The decision to switch the programming language fell right then.}

\subsection{Choosing of the Database and Schema}
\textcolor{newcode}{While the back-end was under development, a set of databases was being tested. After making a few performance tests of different databases as well testing varying data-structural designs it was decided to use mysql since it showed the best results. The first implementation was using Nested-Sets which did not scale, because inserting into the Nested-Set was terribly slow. Inserting into a 10.000 entity channel took about 1 - 5 Seconds. After finishing the back-end with a very simple schema, Constructeev was able to accept 2.000 feedback entries per second on a single 4 core ARM server. Using the Nested-Set the database would have a long queue to work on.}

\textcolor{newcode}{In this version of Constructeev the database schema had an one-to-many relation between channels and feedback entries. Each feedback can also has many feedback entities underneath with will represent replies. Channel and feedback will be related to their properties with a one-to-one relation. A feedback property does only store additional information like the read or unread state or if the feedback has been favorited.}

\textcolor{newcode}{The Nested-Set had one huge advantage over the regular parent-child schema. Counting the children inside a Nested-Set is really easy and can be done with only one calculation \footnote{Subtract the left index of the right index is the number of children if the Nested-Set has not optimized indices.}. Within this schema, which has more performance range, we would have to count every child with the SQL count() function. This call has a linear time complexity of $\mathcal{O}(n)$. Linear time complexity is good, but with an extreme large number of $n$ this takes too much time.}

\textcolor{newcode}{
This problem can be bypassed with a write, memory and time trade-off. Every time a feedback is inserted, the channel row will be updated in relation to the feedback. In this case we have one additional row updated, as a result we get a correct count of feedback entries instantaneously with every channel select, Same with replies on feedback entries. The parent feedback will be updated. The server allows a depth of four replies, which means, that in a \textbf{worst case scenario} the maximum complexity for the correct count is a $\mathcal{O}(\log _2 {n})$ plus row update time, which is less than $\mathcal{O}(\log{2}{n})$. Furthermore we will receive much more reads than writes, especially within the hierarchy.}
	
\textcolor{newcode}{In one of the last month of the developing process, the database had to be changed again. MySQL was replaced with PostgreSQL, hence we strictly used the SQL 2011 standard and only had to change the Ecto adapter. The only reason for this change of plans was for Constructeev being able to integrate into the Amazon web-services data-centers with ease. Amazon's highly scaleable SQL database, called Amazon Redshift which is a modified PostgreSQL, can be used with any standard PostgreSQL database driver/adapter}	

\section{Phoenix Pipelines}
The back-end provides two highly optimized pipelines, because a single ErlangVM is providing binary large objects (blobs) and has, in relation to the blobs, tiny JSON-Object responses or may even only result in a HTTP header with a status code. A single pipline is not optimized for both large and small responses. Scopes are built around all pipelines. All routes with the '/api' prefix are processed by the so called API-pipeline which is optimized for sending JSON responses. The other pipleline has access to the file system, caches last recently used blobs, like images, fonts, HTML templates, precompiled cascading style sheets and JavaScript files. This line then delivers them to the client. 

\section{Front-end}
The front-end is written in JavaScript and uses AngularJS, an open-source web application framework used for developing single-page-applications. By providing a framework for client-side-model–view–controller it aims to simplify both the development and the testing of web applications. With AngularJS it is possible to build feature rich internet applications. The single-page-app is bootstrapped by a very small HTML template, which contains a, by the server pre-processed, cascading style sheet, the minified AngularJS Framework and those extension/dependencies. 

\begin{figure}[H]
  \caption{Startpage Constructeev}
  \centering
    \includegraphics[width=1\textwidth]{images/resdes/001.png}
\end{figure}

Constructeevs client side is divided into several main parts: 
\begin{itemize}
\item MainView
\item ChannelList
\item ChannelDetail
\item AdminView 
\end{itemize}
Every view can have multiple models and each of them has a own factory which handles the API calls and prepairs the data for the controller. 
All of them communicate with the server via a REST like HTTP-API using JSON as dataformat. The API is not a full REST API because sometimes a concurrent state is represented. In this project's case this will be the likes from every channel and the up-voting and down-voting of a feedback. REST APIs solves concurrent problems were the data arriving last is the valid one. This does not work in concurrent problems like for instance when one tries to count a click. It is easy to reproduce those errors: 

\begin{lstlisting}
bash$: curl http://localhost:4000/api/channels/1
{
  "data": {
    "updated_at": "2016-04-22T08:41:03Z",
    "slug": "luntpnbs",
    "name": "Zaam-Dox",
    "likes": 198,
    "id": 1,
    "feedback_counter": 101,
    "email": "ewald.lehner@little.net",
    "description": "Brevity is the soul of wit.",
    "like_url": "/api/channel/1/_like",
    "channel_hash": "8b83774b8932d5ef99c6af660b3f8461"
  }
}
\end{lstlisting}
The JSON represented above is the state of the data in the browser from the user as it is at that exact moment. Now let us call an other client the "like\_url" 50 times. The JSON inside the user's browser is the same state as shown above meanwhile the client wants to like the channel and produce a PATCH-request with following data:
\begin{lstlisting}
{
  "data": {
    "likes": "199",
  }
}
\end{lstlisting}
The client pushes the value of 199 (198+1) likes to the server, which will accept and write down 199 likes in the database, instead of the 249 likes which would be the accurate value. 50 of the 249 likes are dropped in a so called "race conditon". 
REST does not fit here, but instead a RPC (Remote Procedure Call) has been added. This action-URL will be delivered with the API, therefore the RPC-URL can be changed without the client having to be notified or changed because the client does only call the like\_url which is being provided inside the JSON-Object.   

\subsection{Admin View}
 \begin{figure}[H]
  \label{observer}
    \includegraphics[width=1\textwidth]{images/admin}
\end{figure}
\subsection{Feedback View}
\begin{figure}[H]
  \label{observer}
    \includegraphics[width=1\textwidth]{images/user}
\end{figure}
\section{SDLP - Simple Double-Like Prevention}
Each Channel can be liked by anyone. No registration or log-in is required. With a normal implementation a single user could push the "Like-Button" as often as he/she wants to. This would result in the feedback-giving-person being able to  boost his/her own feedback. Also the admin could simply like all positive feedback so there then seems to be more positive feedback altogether. To prevent this from happening a simple double-like prevention has been added to this project. At the beginning it is only client-sided and could be outsmarted with a bit of know-how. The single other rather annoying solution would be to add captchas to every single like-request. 
HTML5 compatible browsers do have a client side storage module called "local storage". It is a key-value store inside the browser of the accessing device. This local storage was designed to hold a large number of keys without affecting the performance of the website. Also the five megabyte limit of a cookie can be  over skipped with  this technology. 
The not sending the local storage  to the origin is another important feature. 
The storage offers a new database-bucket for each origin (domain or protocol). Only web-pages with the same origin can work in this unique bucket. 
SDLP uses the local storage feature and keeps track on which feedback or channel the client has liked. The channel is the key and true or false equals the value. If the client receives a click on the like button, the ID of the feedback-channel will be added to the local storage. On every channel-page load, the client has to look up inside the local storage, wether the channel has been liked or not. If the channel has already been liked, the like button is disabled and can not be clicked again. 
This technique is also used with feedback up-votes and down-votes. In this case the browser also checks if the channel has been liked but instead of disabling the buttons, it will only offer the reverse action. 
For example: An already upvoted feedback can only be down-voted by the same user.

%TODO future preventions

\section{Distributed Mode} \label{distribued_mode}
The distributed mode is in use when a single Phoenix application is running on multiple servers. Here it is not important for the server hardware to be identical, but to be in many differing distributed frameworks. You can use different hardware types since every process is abstracted from the BEAM virtual machine. The main goal is to set up a distributed Phoenix application to get more physical CPU-cores thus the application can work on more cores parallelly.

In distributed systems there are some fallacies which would allow a full-blown horizontal scaling. 
\begin{enumerate}
\item The network is reliable.
\item The latency is zero.
\item The bandwidth is infinite.
\item The network is secure.
\item The topology does not change.
\item There is only one administrator.
\item There is zero transport cost.
\item The network is homogeneous.
\end{enumerate}
\cite{PD001}
In this project the network topology is hidden by the ErlangVM so we assume it is homogeneous and secure. Per definition there is only one administrator and transport costs are almost zero nowadays. Only points one to three can be the bottlenecks for horizontal scaling.
Network can not be reliable. Sometimes network interface cards fail or some more trivial routing of the internet service provider fails, in some cases the network driver can crash.\cite{JH2007}

 Sending messages from one node to another takes time, even if they reside in the same rack and are connected directly to each other. This will slow down the system. If this happens it is important to keep latency as low as possible. 
 
In bench marking a 1Gbit/s connection has been used (for bechmarks see chapter \ref{perf_scale}) and thereby we were strictly limited by connection-speed. When an open  connection exists, passing messages, updating code, passing requests to other servers and dealing with database requests must be possible under all circumstances. With increasing the server's performance more messages from the ErlangVM are sent to each node for synchronization. Also ETS will be more distributed for the session's information and more messages are sent across the network to find the necessary information. 

\ \newline
%--- nur wenn zu wenig text ---
%If the network is not reliable, each node should be able to work on its given task and answer whether it can reach the client, otherwise it has to wait and sync with the other nodes as soon as the network is available again. ???With Phoenix only the pipeline is distributed not sending or receiving a request.??? When a node loses network connection, it will wait for 5000ms and then try to reconnect. If no connection could be reestablished the lost node will discard the work and wait for ???network was???. The node which handles the incoming and outgoing requests will give these requests to another node which then has to try again. Since the standard timeout of browser is somewhere between 60 and 120 seconds, the %application has time to recover. 
%--- ende ----

\section{Sessions}
Sessions information is a kind of state which should be kept within the period of a session. Cookies are often used to store session information, because these cookiesWe were sent to the server with every request . The server needs match the collected information to the session or state he connects to a specific user. Most frameworks keeps session-information inside the main memory of the application. This has one simple reason: Access-time inside the main memory is to slow. 

As described in section \ref{distribued_mode} through adding some servers the application tries to scale as horizontal as possible. When adding a machine, the main memory is not accessible to the other servers. With the standard session management we lose state as well as the session while the clients are redirected to the new server.  A common way to solve this is writing session information into Redis, which is a distributed in-memory data structure storage. 

Constructeev could also use Redis as a distributed in-memory-store for collecting session data, but adding another dependency is unnecessary when the ErlangVM offers almost the same feature. In this project ETS (Erlang Term Storage) is used for storing session data. The only feature, which ETS is missing, is persistent information storage on hard drives. Persistence is not required for storing session information. If the hole system went offline (eg. power outage) the ErlangVM will be restarted and a new secret key will be generated. All cookies generated before the power loss are now invalid, because the secret key has changed. Therefore we do not need persistence, because the security function will invalidate all of the persistent data. In this specific case Constucteev is more performant in recovering form a major issue, because we do not recover useless data.

\section{Testing}
The server side code has been tested with ExUnit, a Unit test framework for Elixir. The API has been tested with the emacs restclient and the client side framework has been tested with Protractor. 
Protractor is a test framework that is running on a real browser, which interacts with the user world.
\textcolor{newcode}{Travis-CI was used for the API and front-end testing as a continuous integration service. This service allows the running of all tests from different commits which are then pushed to github.com. The Travic-CI did not support Elixir or Phoenix applications therefore a custom configuration file has been added to the repository. Now Elixir could be supported and the configuration file was updated to a cleaner and smaller file:}

\begin{verbatim}
before_install:
  - git submodule update --init --recursive
language: elixir
after_script:
  - MIX_ENV=test mix deps.get
  - MIX_ENV=test mix inch.report
\end{verbatim}

\chapter{Usability and Responsive Design}
Usability is a very important aspect of an application. Therefore it is crucial to think about how the functionality and features of the application can be displayed and presented to the user. A lot of effort went into preparing and displaying information in a clear and well-structured way. Sometimes features have to be limited to provide a better usability. This concept occurred in the project and will be described in the next sections. 

Furthermore the application has to be useable with all devices, which obviously do not all have the same screen size. The application has to fit on small screens like mobile-phones, medium sized screens like tablets as well as small notebooks and large screens mostly used as a desktop workstation. All features and informations have to fit on any screen-size, here a responsive design framework helped to develop this function of the application. Via example the next chapter will describe how useability can influence an application's design. At the end of this chapter a overview of the Semantic-UI framework and how it has been used in this work will be given.

\section{Usability of the Feedback Communication Feature}
In this section the usability of the feedback communication feature will be shown and it will be described how it influenced or limited the features of the application. Usability is more important for a web-application than the range of a feature. If the user interface is not easy to use, those features will not be needed at all.

In Constructeev it is possible to answer a feedback discussion message. This allows the building of a recursive order of replies to replies. The API also supports the answering of said message. Regrettably the usability of this dicussion forced the application to show the argumentation to a feedback in a flat chat. A flat chat is a chat where no hirarchy exists and the messages are ordered by time, like in an IRC chat protokoll.  \cite{RFC1459} The following images will illustrate through examples how hirarchial messages limits the usability on mobile devices.
\begin{figure}[h]
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{images/constructeev.jpg}
  \captionof{figure}{Constructeev Flat Chat}
  \label{fig:test1}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{images/reddit}
  \captionof{figure}{Reddit Conversation}
  \label{fig:test2}
\end{minipage}
\centering
  \includegraphics[width=0.4\linewidth]{images/freakshow}
  \captionof{figure}{Wordpress Comments}
  \label{fig:test2}
\end{figure}

\newpage
\section{Responsive Design}
Responsive design is a technique used for building websites or web applications. It provides an optimal experience through covering a wide range of display sizes. A framework, which already has the ability to be responsive, is being used. 
Semantic-UI is easy to use and has many pre-designed collections and modules which support the developer in building a responsive design. The resulting frameworks need to be used with care, because it does not mean every idea is possible in reality and every feature is exactly as usable in small-sized view as it is in the full-sized view. Some parts have been customized for Constructeev, especially features about the mobile navigation menu.
\begin{wrapfigure}{i}{0.5\textwidth}
  \caption{Hamburger Menu}
  \centering
    \includegraphics[width=0.4\textwidth]{images/resdes/004}
\end{wrapfigure}
\textcolor{newcode}{The mobile navigation menu, had to be redesigned for small screen views. In this special case a horizontal menu does not work anymore, or simply consumes too much space on top. If the menu is on the top of the side, the user has to scroll to see the content. This would happen every time a new view was being used. Since the menu is not used constantly, it is acceptable to hide it and provide a commonly known icon, which when activated shows the menu again.
Many web-designers still avoid using the so called "Hamburger Menu", because it is inefficient in displaying menus. The user has to open the menu before he/she can use it. Bad discoverability and operating system design conflicts are the main hindrances why designers choose to use other design patterns.\footnote{Source: https://lmjabreu.com/post/why-and-how-to-avoid-hamburger-menus/}}

\textcolor{newcode}{Usability tests with different occupational groups \footnote{Subjects were: medical doctors, nurses, welding engineers, documentation assistants, law assistants} have clearly shown, that it depends on how the application workflow has been designed. All of the volunteering application testers were happy with the "Hamburger Menu." The placement of the menu-button is consistent in the same left corner on every page. The user dose not have to search for the correct button to click, since there exists only this single menu-button.
Every workflow inside the front-end between the different actions and views has been designed thoroughly. The concept was to provide a fluid flow and not to force the user to move the cursor/finger too much. The user also does not necessarily need the menu to complete different actions.}
 \newpage
\begin{wrapfigure}{i}{0.5\textwidth}
  \caption{Constructeev Modal}
  \centering
    \includegraphics[width=0.4\textwidth]{images/resdes/005}
\end{wrapfigure}
\textcolor{newcode}{The same concept has been applied on the forms used for user input. The user input is not opened on a new page as in many other web-applications. Instead of redirecting the user to a new page, a modal window is opened. The advantage of this design is, that the user does not loose the orientation inside the app on a small screen.}

\textcolor{newcode}{Another important matter for designing a user friendly, responsive application is providing a function to undo a unintended action. This function should not be hidden, it has to be highly visible to give the user the feeling of safety and cancellation.}

\textcolor{newcode}{Using colored buttons makes it easier to navigate on the screen. However "cancel-buttons" are never colored red in Constructeev. The red buttons are reserved for delete/destroy actions. The "cancel-buttons" are intentionally colored gray, to emphasize that they are not irreversible.}

%TODO Mobile Nav Menu, View from Channel on Mobile & Desktop.


\chapter{Performance and Scalability} \label{Performance and Scalability}
\label{perf_scale}
In this chapter the benchmark-process will be described.
This process allows the testing of the scalability of the application, but only to a certain degree. The test system can not represent real-time traffic. Altogether these benchmarks let us see if the application is even able to handle a large amount of requests per second and if it gains a speedup while adding more nodes to the ErlangVM.

\textcolor{newcode}{Performance in general is a amount of work accomplished by a computer system. \footnote{Definition: https://en.wikipedia.org/wiki/Computer\_performance} Work can be split into the following three main sections:}

\begin{itemize}
\item Response time (less is better)
\item Throughput (more is better)
\item Utilization of resources (less is better)
\item Processing speed/requests per second (more is better)
\end{itemize}


\textcolor{newcode}{Benchmarking an application can be difficult. There are quite a lot side-effects which can affect the result of the performance measurement. You will always have to share resources with the operating system and other processes. Resources like disk input/output or high CPU-consumption of other processes can affect the result negatively.}

\textcolor{newcode}{To minimize the side effects a Linux Distribution has been used to run the benchmarks. Every deamon or process which is not essential has been stopped before the test and the latest Erlang \footnote{OTP 18.3 - \url{https://www.erlang.org/news/101}} environment and PostgreSQL \footnote{9.4 - \url{http://apt.postgresql.org/pub/repos/apt/pool/9.4/}} version has been installed.}
\ \\ \newline
\textcolor{newcode}{Separately to the server a client has been set up with the benchmark tools. The clients are located in the same datacenter, are connected to the same server-rack via one router which functions as a hub with a 1Gbit/s connection to the server. A direct connection was not possible and a router/switch was necessary to be able to test with more than one client or server. The clients also need some preparation, because to save money a single client has been optimized to be able to make as much connections per second as possible during a request. The benchmark software has not been coded by myself, thus I had to optimize the system.}

\textcolor{newcode}{To simulate as many concurrent users a possible the benchmark software has to open hundreds of connections to the test server. Therefore some operating system threads are forked and used to open connections. This procedure uses a few file descriptors. The operating system has a hardcoded limit, which means how many file descriptors can be used by the whole system to prevent misuse. We hit this limit very soon so we had to set the limit higher.}
\begin{verbatim}
root@bMalum:~# ulimit -n
10000
root@bMalum:~# ulimit -n 80000 # Setting the new limit
80000
\end{verbatim}

All benchmarks in this chapter are done with a open source tool called "siege". Siege supports basic authentication, cookies, HTTP, HTTPS and FTP protocols and other than with certain tools you can mix GET with PUT/POST and PATCH requests while being gentle with the CPU.
\begin{verbatim} siege -c 200 -b -i  http://127.0.0.1:4000/api/channels/$arg
\end{verbatim} Where -c is the number of concurrent requests and -b flag does not allow any delays between the requests. The last argument which is passed over to the program is the test URL.

\textcolor{newcode}{
Previous tests during the development process have also been done with foreign tools.These tools had some disadvantages over the chosen "siege" stress test tool. Except for the ApacheBench all of them did use a lot more CPU-cycles and were only able to do less than half of the requests per second. Another really interesting discovery made during development mode was, that the logger application, which is used to log and debug the application, crashed and then did not recover. A bug-report has been sent to the corresponding developer.
"WRK" is one of the benchmark tools which used up to 10 times more CPU-power than the ErlangVM used to process and answer the requests. This would result in the necessity of renting more clients to exhaust the server.  
}
%TODO BENCHMARK DESCRIBTION

\section{Read Performance} \label{r_perf}
The test system was an Ubuntu based 14.04 ARM server with a 4 core 1.6GHz CPU and 2GB main memory as well as a 1Gbit/s network interface card.  A custom Marvell Quad-Core ARMADA XP Series SoC was used too.\cite{MarArm}.  
After installing the dependencies, the database has been filled with 1000 channels. Each channel holds about 1600 feedback requests. After the first and recurring benchmarks the server will be restarted so every cache (database, ErlangVM and operating system caches) are cold. The benchmarking software was started on another server. It was linked to the application-server with a 1Gbit/s connection.

\lstset{
    frame=nil,
    language=bash,
    keepspaces=true, 
    numbers=left,
    breaklines=true,
    basicstyle=\ttfamily,
}

\begin{lstlisting}[caption={read benchmark by siege},label=lst:read]
Lifting the server siege...
Transactions:		       32706 hits
Availability:		      100.00 %
Elapsed time:		        6.37 secs
Data transferred:	        8.56 MB
Response time:		        0.04 secs
Transaction rate:	      4234.19 trans/sec
Throughput:		        2.34 MB/sec
Concurrency:		       91.76
Successful transactions:       32706
Failed transactions:	           0
Longest transaction:	        0.10
Shortest transaction:	        0.00
\end{lstlisting}
\textcolor{newcode}{Siege sent 32,706 requests to the server, all of them were answered by the server. On line 7 of Listing \ref{lst:read} we can see that previously 4,234 transactions per second were processed by the server.}

To ensure the correct results the same test has been done with the ApacheBenchmark. Before testing the system again with ApacheBench the server was rebooted to clear all operating system caches and database caches. It showed almost the same request-per-second-result but a increased concurrency level. Thereby  it can be assumed that both benchmarks are equivalent to each other and as correct as benchmarks can get. 
\newpage
\begin{lstlisting}
Server Software:        
Server Hostname:        127.0.0.1
Server Port:            4000

Document Path:          /api/channels/{arg}
Document Length:        292 bytes

Concurrency Level:      100
Time taken for tests:   232.579 seconds
Complete requests:      1000000
Failed requests:        0
Keep-Alive requests:    990049
Total transferred:      555761176 bytes
HTML transferred:       292000000 bytes
Requests per second:    4299.62 [#/sec] (mean)
Time per request:       23.258 [ms] (mean)
Time per request:       0.233 [ms] (mean, across all concurrent requests)
Transfer rate:          2333.56 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       6
Processing:     4   23   3.1     23      86
Waiting:        4   23   3.1     23      86
Total:          4   23   3.1     23      86

Percentage of the requests served within a certain time (ms)
  50%     23
  66%     24
  75%     25
  80%     25
  90%     27
  95%     29
  98%     31
  99%     34
 100%     86 (longest request)
\end{lstlisting}


\begin{figure}[H]
  \caption{ErlangVM Observer}
  \label{observer}
    \includegraphics[width=1\textwidth]{images/observer}
\end{figure}

{\color{newcode}
Erlang has a built in module for observing the state of a single ErlangVM node. This module is called "Observer" and can be started inside the ErlangVM through the following command:
\begin{lstlisting}
:observer.start()
\end{lstlisting}
 Observer is a graphical tool for observing the health and state of the chosen ErlangVM. In the screen-shot shown in figure \ref{observer} the real time scheduler utilization as well as the memory and input/output usage is displayed. We can see that none of the schedulers were at 100\% usage. That lets us come to the assumption, that the server would be able to handle even more requests per second. The test had to be run again with additional clients.}
 
\subsubsection{Coordinating Clients}\label{coordClie}
{\color{newcode}The problem in solving this, was that we needed to run the same benchmark on multiple client-servers at the same time to loot out the limits of the server. In this section the standard reference value is how many request a server can handle in one second. So we can start multiple independent benchmarks at exactly the same time on different clients. The weak point in this case is that we can not synchronize the time on all servers, instead we must force the server to align its system clock to a NTP-server system clock, which leaves plenty of room for errors. The PTP (Precison Time Protokoll) can guarantee correctness under 100$\mu$s inside the local network \cite{PTP}. Before every timed benchmark the system clock gets synchronized and then the tool starts the stress test on a given time for a specific period of time. Hence the tool is started at (almost) exactly the same time and runs for the same amount of time. We have more concurrent users and can simply sum up the request per second of every client. 
} \newline

\begin{table}
 \caption{Read Performance}
\begin{tabular}{c||c|ccc}

Concurrency & Single Client  & \multicolumn{3}{c}{Multiple Clients} \\ 
 & - & Client \#1 & Client \#2 & Sum  \\ 
\hline 
100 & 4180 req/s &  2875 req/s & 2887  req/s& 5.762 req/s \\ 
\hline 
200 & 4269 req/s & 2828 req/s & 2904  req/s& 5.732 req/s \\ 
\hline 
250 & 4462 req/s & 2908 req/s & 3053  req/s& 5.961 req/s \\ 
 
\end{tabular} 
\end{table}

\begin{figure}[H]
  \caption{ErlangVM Observer}
  \label{observer}
    \includegraphics[width=1\textwidth]{images/obser}
\end{figure}
The Erlang Observer shows us, that the server using while beeing under siege 100\% scheduler utilization, which means we hit the maximum. 

\section{Write Performance}\label{w_perf}
{\color{newcode} To test the write performance, the benchmark tool has to be able to send PUT or POST requests. For the write performance test the same experiment setup as shown in section \ref{r_perf} was used. The database has been filled with the same data too. The system has been rebooted to clear all caches of the operating system (file-system cache) and from the database.
Another preparation which had to been done for this test was to create a text-file with JSON-data which will be passed with the POST requests to the database. This file was generated by a small elixir shell script and used Elixir Faker\footnote{https://github.com/igas/faker} to generate the test data.
The benchmark can be called with this command:
\begin{lstlisting}[caption=Siege Post Data, label=siege_post_data]
siege -H 'Content-Type: application/json' 'http://localhost:4000/api/channels/{$1}/feedbacks/' PUT < /home/bMalum/postdata.txt' 
\end{lstlisting}
In Listing \ref{siege_post_data} the siege is started with some new parameters. First the content type has been set to "application/json" to signal the server that the payload is JSON data. The second argument is the tested URL with one parameter to insert data into different channels and the next argument sets the HTTP request type to 'PUT'. The data file is piped into the program and will send the generated data to the server. The clients have been prepared and coordinated with the same like in section \ref{coordClie} } in this test.

\begin{table}
 \caption{Write Performance}
\begin{tabular}{c||c|ccc}

Concurrency & Single Client  & \multicolumn{3}{c}{Multiple Clients} \\ 
 & - & Client \#1 & Client \#2 & Sum  \\ 
\hline 
100 & 2006 req/s &  1351 req/s & 908  req/s& 2259 req/s \\ 
\hline 
200 & 2049 req/s & 1385 req/s & 1129  req/s& 2514 req/s \\ 
\hline 
250 & 2141 req/s & 1424 req/s & 1252  req/s& 2676 req/s \\ 
 
\end{tabular} 
\end{table}

\section{Distributed Performance}\label{d_perf}
%TODO
{\color{newcode}To measure the distributed performance the same client setup as in section \ref{r_perf} and \ref{w_perf} has been used. The server setup does differ in this case and there has been more preparation work. 
For this performance measurement two different setups have been built. The first setup was for using two servers provisioned with a Linux operating system (Ubuntu 14.04 LTS) on a Scaleway C1 unit (4 times 1.6GHz ARM Core, 4GB main memory and 50GB SSD and 1Gbit/s network interface). A third server has been installed with the same operating system, but only a database with fake-test data. This server is simply used as a database server. On the remaining two servers Erlang 18.3 and Elixir 1.2 has been installed. The test servers have not yet been set up and had to be configured to run in a cluster. This has been done by adding a system configuration to the ErlangVM environment.

\begin{lstlisting}[caption={sys.config},label=lst:nodecondig]
[{kernel,
  [{sync_nodes_optional, ['n1@10.0.0.143', 'n2@10.0.0.144']},
    {sync_nodes_timeout, 1000}
  ]}
]
\end{lstlisting}

In the sys.config above two nodes are configured to sync and run as a distributed cluster. A timeout has been set to one second. If the node's clock will drift off more than one second and can't be re-adjusted or the network is not available for longer than one second the second node (n2@10.0.0.144) will stop trying to complete its task an try to reconnect to the cluster in 60 second cycles. 

Each node can be started with the following command:

\begin{lstlisting}
root@titanium$ elixir --name n1@10.0.0.143 --erl "-config sys.config" -S MIX_ENV=prod PORT=80 mix phoenix.server
\end{lstlisting}


This has to be done with the other server too. The parameters have to be modified though.

\begin{lstlisting}
root@titanium$ elixir --name n2@10.0.0.144 --erl "-config sys.config" -S MIX_ENV=prod PORT=80 mix phoenix.server
\end{lstlisting}

The single application is running on both machines using all the resources from both bare metal servers. Both servers are listening to port 80 (standard port for HTTP connections). We can send requests to \url{http://10.0.0.144:80} but we cannot guarantee which node will process the pipeline, only which node did accept the request and send the result. Therefore it would be okay to publish one IP-address from a single node of the cluster.This tactic is not to be recommended.
The best way is to publish all IP-addresses of all nodes. This can be done by creating a so called "Resource Record Set" within the DNS and set the order of the addresses to cyclic. When the domain is resolved, one of the node IP-addresses will be randomly used and all traffic will be distributed to all nodes. A Resource Record Set of this setup would look like this:
\begin{lstlisting}[caption={Resource Record Set},label=lst:nodecondig]
appname.domain.tld.   180  IN  A  10.0.0.144
appname.domain.tld.   180  IN  A  10.0.0.143
\end{lstlisting}

\begin{table}
 \caption{Distributed Performance}
 \label{table_dP}
\begin{tabular}{c||c|cccc}

Concurrency & Single Client  & \multicolumn{4}{c}{Multiple Clients} \\ 
 & - & Client \#1 & Client \#2  & Client \#3 & Sum  \\ 
\hline 
100 & 4096 req/s &  3189 req/s & 2994  req/s & 3218  req/s & 9401 req/s \\ 
\hline 
200 & 4207 req/s & 3212 req/s & 3189  req/s &  3094 req/s & 9495 req/s \\ 
\hline 
250 & 4356 req/s & 3298 req/s & 3247  req/s & 3129  req/s & 9674 req/s \\ 
 
\end{tabular} 
\end{table}
}

{\color{newcode}
With the data from table \ref{table_dP} the distributed mode can achieve in processing "request per second" by a speed up factor from 1.62 to 1.68. Which is a great result for scaling a distributed system \cite{9783642108761}. Of course a higher speed up factor could be achieved with multiple single systems like NodeJS. Projects where stateful connections do play a role can't be carried out so easily with NodeJS. \cite{StatelessvsStatefulWebApps}

\section{Chapter Summary}
In this chapter performance measuring has been described in detail. From the gathered data we can conclude with certainty that Elixir can be used to build a state of the art web service. Most community components written by the Erlang association are built to scale and do not result in smaller bottlenecks as if a similar software written by associations using a different programming language is employed.
It is possible to build a stable an reliable server, which is not only fast in single mode but even performs well when distributed. 
}
\chapter{Conclusion and Future Work}
The developed application shows that it is possible to build a scalebale web service for rallying and storing feedback with a functional language. Through combination of well-known front-end technologies, a full stack application can be built with ease. 
Everyone can create a channel on the reference system and use it without limitations. 
The creator of the channel, also called "channel-administrator" or just administrator will receive a login-key from the system. This key can be easily shared betwixt work groups or the old way, from one person to another. 
Feedback can be sent anonymously, without attaching personal information. Single feedback can be discussed in a chat-like form and up-voted or down-voted. 
The simple benchmark has shown the scalability of the application, to a certain extent, by adding more servers or CPU cores to the ErlangVM.
\textcolor{newcode}{Consturcteev can be downloaded from the public Github Repo and installed on nearly any system. It is integrable into the Amazon Ecosystem for dynamical scaling with using the Amazon Redshift database out of the box
With the plug system of the Phoenix framework the application and the pipelines can be extended at will. The front-end is in an separately git repository, witch is included as a submodule into the Constructeev repository. This makes changing or customizing the front-end easier and allows the development of the front-end to happen independently from the back-end.}

\textcolor{newcode}{The aim for the future is distribute more and more data-communication over the "Phoenix Channel" system. This would allow us to distribute information, such as new feedback entries or comments, to the clients in real-time. The response time is even faster on a "Phoenix Channel" than on a normal channel. Abstractly speaking it would be possible to send messages from an ErlangVM process to the client and then receive the reply directly back on the channel over a socket, which in turn reduces network traffic and unneccesary polling from the client side.}
In future projects the managing and simplifying of diverse channels will be tackled.

Furthermore the development of a Constructeev-Widget will be pushed until it is possible to integrate the widget into other websites as well as export the option-feedback-data. Assigning different colours to different channels will be a new gadget too. Last but not least it will be possible for the user to work on pictures offside Gravatar for a better user experience.
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% ANHANG A
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\cleardoublepage
\appendixheader

% reset counter for section numbering
\setcounter{section}{0}
\setcounter{chapter}{0}
% redefine numbering of sections to A.x
\renewcommand{\thesection}{A.\arabic{section}}
\renewcommand{\thechapter}{A}



\chapter*{Appendix}  % use *-form to suppress numbering
\addcontentsline{toc}{chapter}{Appendix}
% reset counter for section numbering
\setcounter{section}{0}
\setcounter{chapter}{0}
% redefine numbering of sections to A.x
\renewcommand{\thesection}{A.\arabic{section}}
\renewcommand{\thechapter}{A}  


\section{Subsection Appendix}

%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% LITERATURVERZEICHNIS
%+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\cleardoublepage
\nocite{*}
\bibliography{lit}
\addcontentsline{toc}{chapter}{Literaturverzeichnis}

\end{document}


